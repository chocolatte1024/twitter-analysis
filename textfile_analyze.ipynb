{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5aa9d389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.504, 'pos': 0.496, 'compound': 0.7845}\n",
      "{'neg': 0.0, 'neu': 0.809, 'pos': 0.191, 'compound': 0.6369}\n",
      "{'neg': 0.135, 'neu': 0.757, 'pos': 0.108, 'compound': -0.1779}\n",
      "{'neg': 0.0, 'neu': 0.706, 'pos': 0.294, 'compound': 0.3612}\n",
      "{'neg': 0.127, 'neu': 0.582, 'pos': 0.291, 'compound': 0.4767}\n",
      "{'neg': 0.0, 'neu': 0.575, 'pos': 0.425, 'compound': 0.5707}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.444, 'pos': 0.556, 'compound': 0.3612}\n",
      "{'neg': 0.0, 'neu': 0.345, 'pos': 0.655, 'compound': 0.6908}\n",
      "{'neg': 0.0, 'neu': 0.13, 'pos': 0.87, 'compound': 0.7717}\n",
      "{'neg': 0.0, 'neu': 0.794, 'pos': 0.206, 'compound': 0.9081}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.325, 'neu': 0.675, 'pos': 0.0, 'compound': -0.5216}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.514, 'pos': 0.486, 'compound': 0.8578}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.37, 'neu': 0.63, 'pos': 0.0, 'compound': -0.4466}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.444, 'pos': 0.556, 'compound': 0.3612}\n"
     ]
    }
   ],
   "source": [
    "import xlwt\n",
    "import sys\n",
    "import json\n",
    "from datetime import date\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "non_bmp_map = dict.fromkeys(range(0x10000, sys.maxunicode + 1), 0xfffd)\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "wb = xlwt.Workbook()\n",
    "sheet = wb.add_sheet(\"Data\")\n",
    "column_names = ['Negative', 'Neutral', 'Positive', 'Compound', 'Frequency', 'Gender']\n",
    "for i in range(5):\n",
    "    sheet.write(0, i, column_names[i])\n",
    "genders = [0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0]*2\n",
    "\n",
    "def get_date(data):\n",
    "    datelist = data['date'].split('-')\n",
    "    return date(int(datelist[0]), int(datelist[1]), int(datelist[2][:2]))\n",
    "\n",
    "def analyze(index):\n",
    "    count = 0\n",
    "    avgs = {\n",
    "        \"neg\": 0,\n",
    "        \"neu\": 0,\n",
    "        \"pos\": 0, \n",
    "        \"compound\": 0}\n",
    "    date1 = []\n",
    "    date2 = []\n",
    "    with open(files[index]) as f:\n",
    "        for line in f:\n",
    "            count += 1\n",
    "            data = json.loads(line)\n",
    "            \n",
    "            if count==1:\n",
    "                date1 = get_date(data)\n",
    "            date2 = get_date(data)\n",
    "            \n",
    "            content = data[\"rawContent\"].translate(non_bmp_map) \n",
    "            scores = sia.polarity_scores(content)\n",
    "            print(scores)\n",
    "            for sent in scores:\n",
    "                avgs[sent] += scores[sent]\n",
    "    \n",
    "    for sent in avgs:\n",
    "        avgs[sent]/=count\n",
    "    freq = count/((date1-date2).days + 1)\n",
    "    \n",
    "    sheet.write(index+1, 0, avgs['neg'])\n",
    "    sheet.write(index+1, 1, avgs['neu'])\n",
    "    sheet.write(index+1, 2, avgs['pos'])\n",
    "    sheet.write(index+1, 3, avgs['compound'])\n",
    "    sheet.write(index+1, 4, freq)\n",
    "    sheet.write(index+1, 5, genders[index])\n",
    "\n",
    "files = [\"dep_justin\", \"dep_katy\", \"dep_lili\", \"dep_maisie\", \"dep_michael\", \"dep_miley\", \"dep_selena\", \"dep_wayne\",\n",
    "         \"dep_andy\", \"dep_jose\", \"dep_jonathan\", \"dep_busy\", \"dep_pete\",\n",
    "        \"not_justin\", \"not_katy\", \"not_lili\", \"not_maisie\", \"not_michael\", \"not_miley\", \"not_selena\", \"not_wayne\",\n",
    "         \"not_andy\", \"not_jose\", \"not_jonathan\", \"not_busy\", \"not_pete\",]\n",
    "# for i in range(len(files)):\n",
    "#     analyze(i)\n",
    "analyze(0)\n",
    "\n",
    "\n",
    "wb.save('testdata.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307dd581",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
